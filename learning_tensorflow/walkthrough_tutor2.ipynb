{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tutorials i TensorFlow fra Kieth Downing\n",
    "## Sett 2, Autoencoder.\n",
    "\n",
    "Dette eksempelet er et neuralt nett som baserer seg på bits. Den skal få inn bits, så gjennom et hemmlig lag bestående av færre noder enn inputverdier skal den finne tilbake til bits som var i input.\n",
    "\n",
    "Autoencoder er her laget som en egen klasse. Denne klassen kan bygge det neurale nettet med gitte parametere som spesifiserer hvordan nettet skal se ut. \n",
    "\n",
    "Keith downings forklarende tekst:\n",
    "\n",
    "We can extend the basic approach in tfex8 (tutor1.py) to handle \n",
    "1. A 3-layered neural network\n",
    "2. A collection of cases to be learned.  \n",
    "\n",
    "This is a specialized neural network designed to solve one type of classification problem: converting an input string, through a single hidden layer, to a copy of itself on the output end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HENTET FRA autoencoder():\n",
    "def __init__(self,nh=3,lr=.1):\n",
    "    self.cases = TFT.gen_all_one_hot_cases(2**nh)\n",
    "    self.learning_rate = lr\n",
    "    self.num_hiddens = nh\n",
    "    self.build_neural_network(nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her brukes det to variabler som input for metoden. Disse to skal spesifisere nettet. \n",
    "\n",
    "```python\n",
    "\tnh = 3   # number of hidden nodes in the hidden layer\n",
    "\tlr = 0.2 # learning rate used with gradient decent.\n",
    "```\n",
    "\n",
    "Casene hentes fra en genereringsmetode laget av downing. Denne lager bare bit-strenger. Altså sekvenser med bits. Her kommer sekvensene i lengde 2*nh. De hver sekvens er altså dobbelt så lage som antall hidden nodes.\n",
    "\n",
    "Hvis det er tre noder i det hemmelige laget, kommer input i form av:\n",
    "```\n",
    "\t011001\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYGGING AV DET NEURALE NETTET:\n",
    "Under kommer forklaring av koden i metoden \"build_neural_network()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neural_network(self,nh):\n",
    "    ios = 2**nh  # ios = input- and output-layer size\n",
    "    self.w1 = tf.Variable(np.random.uniform(-.1,.1,size=(ios,nh)),name='Weights-1')  # first weight array\n",
    "    self.w2 = tf.Variable(np.random.uniform(-.1,.1,size=(nh,ios)),name='Weights-2') # second weight array\n",
    "    self.b1 = tf.Variable(np.random.uniform(-.1,.1,size=nh),name='Bias-1')  # First bias vector\n",
    "    self.b2 = tf.Variable(np.random.uniform(-.1,.1,size=ios),name='Bias-2')  # Second bias vector\n",
    "    self.input = tf.placeholder(tf.float64,shape=(1,ios),name='Input')\n",
    "    self.target = tf.placeholder(tf.float64,shape=(1,ios),name='Target')\n",
    "    self.hidden = tf.sigmoid(tf.matmul(self.input,self.w1) + self.b1,name=\"Hiddens\")\n",
    "    self.output = tf.sigmoid(tf.matmul(self.hidden,self.w2) + self.b2, name = \"Outputs\")\n",
    "    self.error = tf.reduce_mean(tf.square(self.target - self.output),name='MSE')\n",
    "    self.predictor = self.output  # Simple prediction runs will request the value of outputs\n",
    "    # Defining the training operator\n",
    "    optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "    self.trainer = optimizer.minimize(self.error,name='Backprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det bortgjemte laget skal alltid være halve størrelsen av input - og output lagene. \n",
    "```\n",
    "ios = 2**nh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Han definerer 2 forskjellige sett med vekter her. Det må to sett til fordi det er et hidden-layer mellom input og output. All kommunikasjon skjer gjennom vektmatrisene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}